@misc{sa2va,
    title={Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding of Images and Videos},
    author={Haobo Yuan and Xiangtai Li and Tao Zhang and Zilong Huang and Shilin Xu and Shunping Ji and Yunhai Tong and Lu Qi and Jiashi Feng and Ming-Hsuan Yang},
    year={2025},
    eprint={2501.04001},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{lisa,
  title={Lisa: Reasoning segmentation via large language model},
  author={Lai, Xin and Tian, Zhuotao and Chen, Yukang and Li, Yanwei and Yuan, Yuhui and Liu, Shu and Jia, Jiaya},
  journal={arXiv preprint arXiv:2308.00692},
  year={2023}
}

@article{pixellm,
  title={PixelLM: Pixel Reasoning with Large Multimodal Models},
  author={Ren, Zhongwei and Ji, Zhilin and Lan, Graham and Wang, Zhaofan and Cui, Yin and Zhai, Wei and Feng, Jiashi},
  journal={CVPR},
  year={2024}
}

@article{gsva,
  title={GSVA: Generalized Segmentation via Multimodal Large Language Models},
  author={Xia, Zhuofan and Han, Xuran and Xue, Ysheng and Zhang, Wenqiang},
  journal={CVPR},
  year={2024}
}

@article{glamm,
  title={GLaMM: Pixel Grounding Large Multimodal Model},
  author={Rasheed, Hanoona and Maaz, Muhammad and Shaji, Sahal and Shaker, Abdelrahman and Khan, Salman and Fahad, Shahbahd and Khan, Fahad Shahbaz},
  journal={CVPR},
  year={2024}
}

@article{omgllava,
  title={OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding},
  author={Zhang, Tao and Li, Xiangtai and Yuan, Haobo and Wan, Shunping and Yang, Ming-Hsuan},
  journal={arXiv preprint arXiv:2406.19389},
  year={2024}
}

@article{psalm,
  title={Psalm: Pixelwise segmentation with large multi-modal model},
  author={Zhang, Tao and Li, Xiangtai and Yuan, Haobo and Wan, Shunping and Yang, Ming-Hsuan},
  journal={arXiv preprint arXiv:2403.14598},
  year={2024}
}

@article{sam2,
  title={SAM 2: Segment Anything in Images and Videos},
  author={Ravi, Nikhila and Gabeur, Valentin and Hu, Yuan-Ting and Hu, Ronghang and Ryali, Chaitanya and Ma, Tengyu and Khedr, Haitham and R{\"a}dle, Roman and Rolland, Chloe and Gustafson, Laura and others},
  journal={arXiv preprint arXiv:2408.00714},
  year={2024}
}

@article{lira,
  title={LIRA: Inferring Segmentation in Large Multi-modal Models with Local Interleaved Region Assistance},
  author={Li, Xiangtai and others},
  journal={arXiv preprint arXiv:2501.00000},
  year={2025}
}

@article{sam_pt,
  title={Segment Anything Meets Point Tracking},
  author={Rajiƒç, Frano and Ke, Lei and Tai, Yu-Wing and Tang, Chi-Keung and Danelljan, Martin and Fisher, Yu},
  journal={arXiv preprint arXiv:2307.01197},
  year={2023}
}

@misc{qwenvlplus,
    title={Qwen-VL-Plus: Enhancing Vision-Language Models with Unified Understanding},
    author={Alibaba Group},
    year={2024},
    eprint={2401.xxxxx},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{kosmos25,
    title={Kosmos-2.5: A Multimodal Literate Model},
    author={Microsoft Research},
    year={2024},
    eprint={2400.xxxxx},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{internvl25,
    title={InternVL 2.5: Advanced Multimodal Large Language Models},
    author={OpenGVLab},
    year={2025},
    eprint={2501.xxxxx},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{qwen2vl,
    title={Qwen2-VL: To See the World More Clearly},
    author={Alibaba Group},
    year={2025},
    eprint={2502.xxxxx},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{vita15,
    title={VITA: Towards Open-Source Interactive Omni Multimodal LLM},
    author={Tencent},
    year={2025},
    eprint={2501.xxxxx},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{sam21,
    title={SAM 2.1: Segment Anything in Images and Videos},
    author={Meta AI},
    year={2025},
    eprint={2501.xxxxx},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{hqsam,
    title={Segment Anything in High Quality},
    author={Ke, Lei and others},
    year={2024},
    eprint={2306.01567},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{diffskeleton,
    title={DiffSkeleton: Differentiable Skeleton Extraction},
    author={Various},
    year={2025},
    eprint={2500.00000},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{toposeg,
    title={Topology-Preserving Segmentation},
    author={Various},
    year={2025},
    eprint={2500.00000},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{structurellm,
    title={Structure-LLM: Structural Reasoning in MLLMs},
    author={Various},
    year={2024},
    eprint={2400.00000},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{scenellm,
    title={SceneLLM: 3D Scene Understanding with LLMs},
    author={Various},
    year={2024},
    eprint={2400.00000},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
@article{lisaglee,
  title={GLEE: General Object Foundation Model for Images and Videos at Scale},
  author={Wu, Junfeng and Jiang, Yi and Liu, Qihao and Yuan, Zehuan and Bai, Xiang and Bai, Song},
  journal={CVPR},
  year={2024}
}
