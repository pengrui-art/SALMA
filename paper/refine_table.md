### 论文 vs 代码不一致修正表

| 论文章节 / 涉及概念             | 论文当前描述 (Paper Claims)                                                                                                                                                         | 代码实际实现 (Code Implementation)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | 修改建议 / 备注                                                                                                                                                |
| :------------------------------ | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **3.2 Mask Prior 生成器** | **轻量级 1x1 卷积** `<br>`“lightweight auxiliary head, ... two 1x1 convolution layers”                                                                                    | **复用 SAM2 Mask Decoder** `<br>`[mask_source=&#34;pred&#34;](vscode-file://vscode-app/d:/Software/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-browser/workbench/workbench.html) 调用 [sam2_model._forward_sam_heads](vscode-file://vscode-app/d:/Software/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-browser/workbench/workbench.html)`<br>`(包含 Transformer 的重型解码器)                                                                                                              | **重大差异** 。代码并未实现轻量级卷积头，而是利用预训练的 SAM2 解码器生成 Mask Prior。需修改方法描述或更新代码以匹配论文。                               |
| **3.2 Attention 方向**    | **文本查询视觉 (Text queries Visual)** `<br>`公式 QiKjT**Q**iK**j**T，Q**Q**=Text, K**K**=Visual`<br>`目的是更新 Text 特征。                      | **视觉查询文本 (Visual queries Text)** `<br>models/cma.py`: `q=visual`, `k=v=text<br>`目的是将文本语义注入视觉特征。                                                                                                                                                                                                                                                                                                                                                                                         | **方向完全相反** 。代码逻辑是 `Visual (Query) -> Text (Key)`。即“Visual token 寻找相关的 Text token”。需重写公式 (3) 和相关描述。                    |
| **3.2 Token 选择策略**    | **全量交互** `<br>`默认为所有文本 Token 参与注意力计算。                                                                                                                    | **Top-K Token 路由** `<br>configs/..exp2.py`: `cma_topk_tokens=2<br>``models/cma.py`: 仅选取得分最高的 K 个文本 Token 参与交互。                                                                                                                                                                                                                                                                                                                                                                             | 代码中包含明显的 Token 稀疏化/选择机制，论文未提及及此“Top-K”策略，建议补充。                                                                                |
| **3.2 Gating 作用位置**   | **Attention Map 加权** `<br>`公式 (3): Mask (G**G**) 应用在 Softmax 后的概率分布上 (A^i,j=⋯⋅Gj**A**^**i**,**j****=**⋯**⋅**G**j**)。 | **Attention Output 加权** `<br>`[cma.py](vscode-file://vscode-app/d:/Software/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-browser/workbench/workbench.html): Mask 应用在注意力层的输出特征上 ([attn_out = attn_out * gate](vscode-file://vscode-app/d:/Software/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-browser/workbench/workbench.html))。                                                                                                                                             | 论文描述的是“引导注意力看哪里”，代码实现的是“过滤注意力输出的结果”。数学含义不同，需修正公式 (4)。                                                         |
| **3.2 Warm-up 策略**      | **Mask 强度渐变** `<br>`公式 Gfinal=1+ω(G−1)**G**f**ina**l=**1**+**ω**(**G**−**1**)`<br>`控制 Mask 从“全通”到“生效”。                                 | **模块残差权重渐变** `<br>`[cma_warmup_hook.py](vscode-file://vscode-app/d:/Software/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-browser/workbench/workbench.html): 控制整个 CMA 模块的残差系数 γ**γ** (`scale * gamma`)。`<br>`控制 CMA 模块从“无”到“有”。                                                                                                                                                                                                                            | 代码是对整个 Cross-Attention 模块进行 Warm-up，而不是针对 Mask 门控本身。                                                                                      |
| **4.1 学习率**            | **1e-4** `<br>`“learning rate of 1e-4”                                                                                                                                    | **4e-5** `<br>configs/..exp2.py`: `lr = 4e-5`                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | 需修正实验设置部分的数值。                                                                                                                                     |
| **4.1 训练周期**          | **“First few epochs”** `<br>`提到 Warm-up 持续前几个 epoch。                                                                                                              | **1 Epoch** `<br>max_epochs = 1``<br>`Warm-up 持续前 10% 的迭代步数 (`warmup_ratio=0.1`)。                                                                                                                                                                                                                                                                                                                                                                                                                   | 既然只训练 1 个 Epoch，无法使用“前几个 Epoch”这种表述。建议改为“initial 10% of iterations”。                                                               |
| **4.2 训练数据集**        | **隐含/仅提及 Evaluation 集** `<br>`主要列举了 RefCOCO, DAVIS, MeVis。`<br>`似乎暗示仅在这些数据上微调。                                                                  | **混合多任务数据集** `<br>train_dataset` 包含了：`<br>`1. RefCOCO (x4倍采样)`<br>`2. Video (ReVOS x10, MeVIS x4)`<br>`3.  **GCG (Glamm, Flickr, etc.)** `<br>`4.  **Osprey (Region-Text)** `<br>`5. SAM2 Pseudo Video                                                                                                                                                                                                                                                                      | 代码实际上使用了非常庞大的混合数据集（Image+Video+Grounded Chat）进行训练，并非仅仅微调 Ref/Seg 任务。这显著增强了模型的泛化能力，论文应明确列出这些训练数据。 |
| **4.3 损失函数细节**      | **TMC Loss (单向)** `<br>`公式 (5) 仅描述了 LText→Vis**L**T**e**x**t**→**Vi**s。                                                                  | **TMC Loss (双向对称)** `<br>losses.py`: `0.5 * (loss_i + loss_t)<br>`包含 Text ↔**↔** Visual 双向对比。                                                                                                                                                                                                                                                                                                                                                                                               | 这是一个较小的技术细节，论文公式通常可以简化，但代码确实是双向 Symmetric InfoNCE。                                                                             |
| **Mask 来源配置**         | **GT / Predicted ?** `<br>`理论上可用 GT。                                                                                                                                  | **Predicted Only** `<br>`[mask_source=&#34;pred&#34;](vscode-file://vscode-app/d:/Software/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-browser/workbench/workbench.html)`<br>`且代码中 [gt](vscode-file://vscode-app/d:/Software/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-browser/workbench/workbench.html) 分支未实现逻辑 ([mask_logits_for_cma = None](vscode-file://vscode-app/d:/Software/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-browser/workbench/workbench.html)). | 确认论文中没有声称使用了 GT 作为 Prior 即可。代码目前只支持 Predicted Mask。                                                                                   |
