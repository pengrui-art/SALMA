@article{sa2va,
    title   = {{Sa2VA}: Marrying {SAM2} with {LLaVA} for Dense Grounded Understanding of Images and Videos},
    author  = {Haobo Yuan and Xiangtai Li and Tao Zhang and Zilong Huang and Shilin Xu and Shunping Ji and Yunhai Tong and Lu Qi and Jiashi Feng and Ming-Hsuan Yang},
    journal = {arXiv preprint arXiv:2501.04001},
    year    = {2025}
}

@inproceedings{lisa,
    title     = {{LISA}: Reasoning Segmentation via Large Language Model},
    author    = {Xin Lai and Zhuotao Tian and Yukang Chen and Yanwei Li and Yuhui Yuan and Shu Liu and Jiaya Jia},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2024}
}

@inproceedings{pixellm,
    title     = {{PixelLM}: Pixel Reasoning with Large Multimodal Models},
    author    = {Zhongwei Ren and Zhilin Ji and Graham Lan and Zhaofan Wang and Yin Cui and Wei Zhai and Jiashi Feng},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2024}
}

@inproceedings{gsva,
    title     = {{GSVA}: Generalized Segmentation via Multimodal Large Language Models},
    author    = {Zhuofan Xia and Xuran Han and Ysheng Xue and Wenqiang Zhang},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2024}
}

@inproceedings{glamm,
    title     = {{GLaMM}: Pixel Grounding Large Multimodal Model},
    author    = {Hanoona Rasheed and Muhammad Maaz and Sahal Shaji and Abdelrahman Shaker and Salman Khan and Shahbahd Fahad and Fahad Shahbaz Khan},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2024}
}

@article{omgllava,
    title     = {{OMG-LLaVA}: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding},
    author    = {Tao Zhang and Xiangtai Li and Haobo Yuan and Shunping Wan and Ming-Hsuan Yang},
    journal   = {arXiv preprint arXiv:2406.19389},
    year      = {2024}
}

@article{psalm,
    title     = {{PSALM}: Pixelwise Segmentation with Large Multi-Modal Model},
    author    = {Tao Zhang and Xiangtai Li and Haobo Yuan and Shunping Wan and Ming-Hsuan Yang},
    journal   = {arXiv preprint arXiv:2403.14598},
    year      = {2024}
}

@article{sam2,
    title   = {{SAM} 2: Segment Anything in Images and Videos},
    author  = {Nikhila Ravi and Valentin Gabeur and Yuan-Ting Hu and Ronghang Hu and Chaitanya Ryali and Tengyu Ma and Haitham Khedr and Roman RÃ¤dle and Chloe Rolland and Laura Gustafson and others},
    journal = {arXiv preprint arXiv:2408.00714},
    year    = {2024}
}

@article{lira,
    title     = {{LIRA}: Inferring Segmentation in Large Multi-modal Models with Local Interleaved Region Assistance},
    author    = {Xiangtai Li and others},
    journal   = {arXiv preprint arXiv:2501.00000},
    year      = {2025}
}



@inproceedings{lisaglee,
    title     = {{GLEE}: General Object Foundation Model for Images and Videos at Scale},
    author    = {Junfeng Wu and Yi Jiang and Qihao Liu and Zehuan Yuan and Xiang Bai and Song Bai},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2024}
}

@inproceedings{lavt,
    title     = {{LAVT}: Language-Aware Vision Transformer for Referring Image Segmentation},
    author    = {Zhao Yang and Jiaqi Wang and Yansong Tang and Kai Chen and Hengshuang Zhao and Philip HS Torr},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2022}
}

@inproceedings{cris,
    title     = {{CRIS}: {CLIP}-Driven Referring Image Segmentation},
    author    = {Zhaoqing Wang and Yu Lu and Qiang Li and Xunqiang Tao and Yandong Guo and Mingming Gong and Tongliang Liu},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2022}
}

@inproceedings{soc,
    title     = {{SOC}: Semantic-Assisted Object Cluster for Referring Video Object Segmentation},
    author    = {Zhuoyan Luo and Yicheng Xiao and Yong Liu and Yitong Li and Yujiu Lu and Gaurav Sharma},
    booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
    year      = {2023}
}

@article{risam,
    title     = {{RISAM}: Referring Image Segmentation via Mutual-Aware Attention Features},
    author    = {Mengxi Zhang and Yiming Liu and Xiangjun Yin},
    journal   = {IEEE Transactions on Circuits and Systems for Video Technology},
    year      = {2023}
}

@inproceedings{maskgrounding,
    title     = {Mask Grounding for Referring Image Segmentation},
    author    = {Yong Xien Chng and Henry Zheng and Yizeng Han and Xuannan Liu and Mohan Kankanhalli},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2024}
}

@inproceedings{ssa,
    title     = {Semantic and Sequential Alignment for Referring Video Object Segmentation},
    author    = {Feiyu Pan and Hao Fang and Fangkai Li},
    booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
    year      = {2025}
}

@inproceedings{mattnet,
    title     = {{MattNet}: Modular Attention Network for Referring Expression Comprehension},
    author    = {Licheng Yu and Zhe Lin and Xiaohui Shen and Jimei Yang and Xin Lu and Alan L Yuille},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2018}
}

@inproceedings{mcn,
    title     = {Segmentation from Natural Language Expressions},
    author    = {Ronghang Hu and Marcus Rohrbach and Trevor Darrell},
    booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
    year      = {2016}
}





@inproceedings{reftr,
    title     = {Referencing Transformer for Referring Image Segmentation},
    author    = {Muguang Li and Leonid Sigal},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2021}
}

@inproceedings{vlt,
    title     = {Vision-Language Transformer and Query Generation for Referring Segmentation},
    author    = {Henghui Ding and Chang Liu and Suchen He and Xudong Jiang and Chen Change Loy},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    year      = {2021}
}

@inproceedings{referformer,
    title     = {{ReferFormer}: A Simple Baseline for Referring Image Segmentation},
    author    = {Jianzong Wu and Yi Jiang and Peize Sun and Zehuan Yuan and Ping Tan},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2022}
}

@inproceedings{mttr,
    title     = {End-to-End Referring Video Object Segmentation with Multimodal Transformers},
    author    = {Adam Botach and Evgenii Zheltonozhskii and Chaim Baskin},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2022}
}

@inproceedings{mevis,
    title     = {{MeViS}: A Large-scale Benchmark for Video Segmentation with Motion Expressions},
    author    = {Henghui Ding and Chang Liu and Suchen He and Xudong Jiang and Philip HS Torr and Song Bai},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    year      = {2023}
}

@inproceedings{uninext,
    title     = {Universal Instance Perception as Object Discovery and Retrieval},
    author    = {Bin Yan and Yi Jiang and Jianzong Wu and Dong Wang and Zehuan Yuan and Ping Luo},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2023}
}

@article{chatgpt,
    title     = {{ChatGPT}: Optimizing Language Models for Dialogue},
    author    = {{OpenAI}},
    journal   = {OpenAI Blog},
    year      = {2022}
}

@article{gpt4,
    title     = {{GPT}-4 Technical Report},
    author    = {{OpenAI}},
    journal   = {arXiv preprint arXiv:2303.08774},
    year      = {2023}
}

@article{gemini,
    title     = {{Gemini}: a family of highly capable multimodal models},
    author    = {{Gemini Team}},
    journal   = {arXiv preprint arXiv:2312.11805},
    year      = {2023}
}

@article{llama,
    title     = {{LLaMA}: Open and Efficient Foundation Language Models},
    author    = {Hugo Touvron and others},
    journal   = {arXiv preprint arXiv:2302.13971},
    year      = {2023}
}

@inproceedings{internvl,
    title     = {{InternVL}: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks},
    author    = {Zhe Chen and others},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2024}
}





@article{minigpt4,
    title     = {{MiniGPT}-4: Enhancing Vision-Language Understanding with Advanced Large Language Models},
    author    = {Deyao Zhu and others},
    journal   = {arXiv preprint arXiv:2304.10592},
    year      = {2023}
}





@article{qwen,
    title     = {{Qwen-VL}: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond},
    author    = {Jinze Bai and others},
    journal   = {arXiv preprint arXiv:2308.12966},
    year      = {2023}
}



@inproceedings{rela,
    title     = {{ReLA}: Relative Label Assignment for Referring Image Segmentation},
    author    = {Chang Liu and others},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    year      = {2023}
}

@inproceedings{seqtr,
    title     = {{SeqTR}: A Simple, Alignment-Aware Transformer for Referring Image Segmentation},
    author    = {Chaoyang Zhu and others},
    booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
    year      = {2022}
}



@inproceedings{clip,
    title     = {Learning Transferable Visual Models From Natural Language Supervision},
    author    = {Alec Radford and others},
    booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
    year      = {2021}
}







@inproceedings{seem,
    title     = {{SEEM}: Segment Everything Everywhere All at Once},
    author    = {Xueyan Zou and others},
    booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
    year      = {2023}
}

@inproceedings{seggpt,
    title     = {{SegGPT}: Segmenting Everything In Context},
    author    = {Xinlong Wang and others},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    year      = {2023}
}

@inproceedings{openseed,
    title     = {{OpenSeed}: A Unified Foundation Model for Open-Vocabulary Segmentation},
    author    = {Hao Zhang and others},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2023}
}

@inproceedings{cutler,
    title     = {Cut and Learn for Unsupervised Object Detection and Instance Segmentation},
    author    = {Xudong Wang and others},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2023}
}

@article{videollava,
    title     = {{Video-LLaVA}: Learning United Visual Representation by Alignment Before Projection},
    author    = {Bin Lin and others},
    journal   = {arXiv preprint arXiv:2311.10122},
    year      = {2023}
}





















@article{videolisa,
    title     = {One Token to Seg Them All: Language Instructed Reasoning Segmentation in Videos},
    author    = {Sheng Jin and others},
    journal   = {arXiv preprint arXiv:2409.19603},
    year      = {2024}
}

@article{visa,
    title     = {{VISA}: Reasoning Video Object Segmentation via Large Language Models},
    author    = {Cilin Yan and Haochen Wang and Shilin Yan and Xiaolong Jiang and Yao Hu and Guoliang Kang and Weidi Xie and Efstratios Gavves},
    journal   = {arXiv preprint arXiv:2407.11325},
    year      = {2024}
}

@inproceedings{mmbench,
    title     = {{MMBench}: Is Your Multi-modal Model an All-around Player?},
    author    = {Yuan Liu and others},
    booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
    year      = {2024}
}

@article{mme,
    title     = {{MME}: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models},
    author    = {Chaoyou Fu and others},
    journal   = {arXiv preprint arXiv:2306.13394},
    year      = {2023}
}

@article{videomme,
    title     = {{Video-MME}: The First-Ever Comprehensive Evaluation Benchmark of Multi-modal {LLM}s in Video Analysis},
    author    = {Chaoyou Fu and others},
    journal   = {arXiv preprint arXiv:2405.21075},
    year      = {2024}
}

@inproceedings{seedbench,
    title     = {{SEED-Bench}: Benchmarking Multimodal Large Language Models},
    author    = {Bohao Li and others},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2024}
}

@inproceedings{pope,
    title     = {Evaluating Object Hallucination in Large Vision-Language Models},
    author    = {Yifan Li and others},
    booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)},
    year      = {2023}
}

@article{llama2,
    title     = {{Llama} 2: Open Foundation and Fine-Tuned Chat Models},
    author    = {Hugo Touvron and others},
    journal   = {arXiv preprint arXiv:2307.09288},
    year      = {2023}
}

@inproceedings{llava15,
    title     = {Improved Baselines with Visual Instruction Tuning},
    author    = {Haotian Liu and others},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2024}
}

@article{llavanext,
    title     = {{LLaVA-NeXT}: Improved reasoning, {OCR}, and world knowledge},
    author    = {Haotian Liu and others},
    journal   = {LLaVA Blog},
    year      = {2024}
}

@inproceedings{cambrian,
    title     = {{Cambrian-1}: A Fully Open, Vision-Centric Exploration of Multimodal {LLM}s},
    author    = {Shengbang Tong and others},
    booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
    year      = {2024}
}

@article{internlm,
    title     = {{InternLM-XComposer2}: Mastering Free-form Text-Image Composition and Comprehension in Vision-Language Large Model},
    author    = {Xiaoyi Dong and others},
    journal   = {arXiv preprint arXiv:2401.16420},
    year      = {2024}
}

@inproceedings{internlm_hd,
    title     = {{InternLM-XComposer2-4KHD}: A Pioneering Large Vision-Language Model Handling Resolutions from 336 Pixels to 4K {HD}},
    author    = {Xiaoyi Dong and others},
    booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
    year      = {2024}
}

@article{qwen2,
    title     = {{Qwen2} Technical Report},
    author    = {An Yang and others},
    journal   = {arXiv preprint arXiv:2407.10671},
    year      = {2024}
}












@inproceedings{videochatgpt,
    title     = {{Video-ChatGPT}: Towards Detailed Video Understanding via Large Vision and Language Models},
    author    = {Muhammad Maaz and others},
    booktitle = {Proceedings of the Association for Computational Linguistics (ACL)},
    year      = {2024}
}

@inproceedings{univs,
    title     = {{UniVS}: Unified and Universal Video Segmentation with Prompts as Queries},
    author    = {Minghan Li and others},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2024}
}

@inproceedings{dvis,
    title     = {{DVIS}: Decoupled Video Instance Segmentation Framework},
    author    = {Tao Zhang and others},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    year      = {2023}
}

@inproceedings{tubelink,
    title     = {{Tube-Link}: A Flexible Cross Tube Baseline for Universal Video Segmentation},
    author    = {Xiangtai Li and others},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    year      = {2023}
}

@inproceedings{omgseg,
    title     = {{OMG-Seg}: Is One Model Good Enough For All Segmentation?},
    author    = {Xiangtai Li and others},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2024}
}





@inproceedings{mmmu,
    title     = {{MMMU}: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert {AGI}},
    author    = {Xiang Yue and others},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2024}
}



@inproceedings{sam,
    title     = {{Segment Anything}},
    author    = {Alexander Kirillov and Eric Mintun and Nikhila Ravi and Hanzi Mao and Chloe Rolge and Laura Gustafson and Tete Xiao and Spencer Whitehead and Alexander C Berg and Wan-Yen Lo and others},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    year      = {2023}
}



@inproceedings{cmsa,
    title     = {Cross-Modal Self-Attention Network for Referring Image Segmentation},
    author    = {Linwei Ye and Mrigank Rochan and Zhi Liu and Yang Wang},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2019}
}

@inproceedings{efn,
    title     = {Encoder Fusion Network with Co-Attention Embedding for Referring Image Segmentation},
    author    = {Guang Feng and Zhiwei Hu and Li Zhang and Huchuan Lu},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2021}
}

@inproceedings{cmmasksd,
    title     = {{CM-MaskSD}: Cross-Modality Masked Self-Distillation for Referring Image Segmentation},
    author    = {Wen Wang and Jing Liu and Xudong He},
    booktitle = {Proceedings of the ACM International Conference on Multimedia (ACM MM)},
    year      = {2023}
}

@article{tfanet,
    title     = {{TFANet}: Three-Stage Image-Text Feature Alignment Network for Robust Referring Image Segmentation},
    author    = {Qi Lu and Yi Xie and Jian Zhang},
    journal   = {arXiv preprint arXiv:2509.13070},
    year      = {2025}
}

@inproceedings{refmask3d,
    title     = {{RefMask3D}: Language-Guided Transformer for 3D Referring Segmentation},
    author    = {Shitong He and Henghui Ding},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2024}
}
@inproceedings{refcoco,
  title={{ReferItGame}: Referring to Objects in Photographs of Natural Scenes},
  author={Kazemzadeh, Sahar and Ordonez, Vicente and Matten, Mark and Berg, Tamara L},
  booktitle={EMNLP},
  year={2014}
}

@inproceedings{refcocog,
  title={Generation and Comprehension of Unambiguous Object Descriptions},
  author={Mao, Junhua and Huang, Jonathan and Toshev, Alexander and Camburu, Oana and Yuille, Alan L and Murphy, Kevin},
  booktitle={CVPR},
  year={2016}
}

@article{davis2017,
  title={The 2017 {DAVIS} Challenge on Video Object Segmentation},
  author={Pont-Tuset, Jordi and Perazzi, Federico and Caelles, Sergi and Arbel{\'a}ez, Pablo and Sorkine-Hornung, Alexander and Van Gool, Luc},
  journal={arXiv preprint arXiv:1704.00675},
  year={2017}
}

@inproceedings{ytvos,
  title={{YouTube-VOS}: A Large-Scale Video Object Segmentation Benchmark},
  author={Xu, Ning and Yang, Linjie and Fan, Yuchen and Yang, Dingcheng and Yue, Yu and Liang, Yuchen and PRICE, Francis and Cohen, Scott and Huang, Thomas},
  booktitle={ECCV},
  year={2018}
}

@article{llamavid,
  title={LLaMA-VID: An Image-to-Video Token for Video Understanding},
  author={Li, Yanwei and Wang, Chengyao and Wu, Jindong},
  journal={arXiv preprint arXiv:2311.17043},
  year={2023}
}

@article{mplugowl3,
  title={mPLUG-Owl3: Towards Long Image-Sequence Understanding in Multi-Modal Large Language Models},
  author={Ye, Jianguo and others},
  journal={arXiv preprint arXiv:2408.04840},
  year={2024}
}


@article{lasagna,
    title     = {{LaSagnA}: Language-based Segmentation Assistant for Complex Queries},
    author    = {Cong Wei and Haoxian Tan and Yujie Zhong and Yujiu Yang and Lin Ma},
    journal   = {arXiv preprint arXiv:2404.02646},
    year      = {2024}
}

@article{llavag,
    title     = {{LLaVA-Grounding}: Grounded Visual Chat with Large Multimodal Models},
    author    = {Hao Zhang and Hongyang Li and Feng Li and Tianhe Ren and Xueyan Zou and Shilong Liu and Shijia Huang and Jianfeng Gao and Lei Zhang and Chunyuan Li and Jianwei Yang},
    journal   = {arXiv preprint arXiv:2312.02949},
    year      = {2023}
}

@inproceedings{chatunivi24,
    title     = {{Chat-UniVi}: Unified Visual Representation Empowers Large Language Models with Image and Video Understanding},
    author    = {Peng Jin and Ryuichi Takanobu and Caiwan Zhang and Xiaochun Cao and Li Yuan},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2024}
}

@inproceedings{osprey24,
    title     = {{Osprey}: Pixel Understanding with Visual Instruction Tuning},
    author    = {Yuan Yao and Tianyu Gisiger and Yuxin Peng and others},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2024}
}

@article{internvl25new,
    title     = {Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling},
    author    = {Zhe Chen and others},
    journal   = {arXiv preprint arXiv:2412.05271},
    year      = {2024}
}
